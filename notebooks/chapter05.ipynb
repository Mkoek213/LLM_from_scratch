{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b2e228a6",
   "metadata": {},
   "source": [
    "## Pretraining on unlabeled data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88f13d70",
   "metadata": {},
   "source": [
    "### 1) Evaluating generative text models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a47cd118",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import GPTModel\n",
    "import torch\n",
    "\n",
    "GPT_CONFIG_124M = {\n",
    "    \"vocab_size\": 200019,\n",
    "    \"context_length\": 256,\n",
    "    \"emb_dim\": 768,\n",
    "    \"n_heads\": 12,\n",
    "    \"n_layers\": 12,\n",
    "    \"drop_rate\": 0.1,\n",
    "    \"qkv_bias\": False\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ba679878",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(123)\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d08ab0fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "from utils import generate_text_simple\n",
    "\n",
    "def text_to_token_ids(text, tokenizer):\n",
    "    encoded = tokenizer.encode(text, allowed_special={\"<|endoftext|>\"})\n",
    "    encoded_tensor = torch.tensor(encoded).unsqueeze(0)\n",
    "    return encoded_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "49cfb5b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input IDs: tensor([[152687,   8811,   3705, 155653,    286,   2453,   3008,  12637]])\n"
     ]
    }
   ],
   "source": [
    "start_context = \"Pierwszy dzień wiosny jest\"\n",
    "tokenizer = tiktoken.get_encoding(\"o200k_base\")\n",
    "input_ids = text_to_token_ids(start_context, tokenizer)\n",
    "print(\"Input IDs:\", input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c06c7ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def token_ids_to_text(token_ids, tokenizer):\n",
    "    decoded = tokenizer.decode(token_ids.squeeze(0).tolist())\n",
    "    return decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c73251bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token IDs to text: <function token_ids_to_text at 0x7c6252be5ee0>\n"
     ]
    }
   ],
   "source": [
    "token_ids_to_text(input_ids, tokenizer)\n",
    "print(\"Token IDs to text:\", token_ids_to_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2126a171",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_ids = generate_text_simple(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(start_context, tokenizer),\n",
    "    max_new_tokens=10,\n",
    "    context_size=GPT_CONFIG_124M[\"context_length\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4116fa9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([152687,   8811,   3705, 155653,    286,   2453,   3008,  12637,  43195,\n",
       "        173252,  76557,  76131,  48593,  63588, 185378,  49039, 150980, 164286])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_ids.squeeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8b33575e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Pierwszy dzień wiosny jest dressed ఎమ్మ(ll proactiveddietrade الأراضي исслед mike العمليات'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_ids_to_text(token_ids, tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37d9b2e5",
   "metadata": {},
   "source": [
    "### 2) Calculating the text generation loss: cross-entropy and perplexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bf67719e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[    54, 148556,  51201,   6517,   6248, 104788,  21589,    621]])\n",
      "tensor([[100256,   6248, 104788,  21589,    621,    460,  28178,     84]])\n"
     ]
    }
   ],
   "source": [
    "inputs = text_to_token_ids(\"Wszystkie drogi prowadzą do\", tokenizer)\n",
    "print(inputs)\n",
    "targets = text_to_token_ids(\"drogi prowadzą do Rzymu\", tokenizer)\n",
    "print(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0399ace9",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    logits = model(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "65f35bf7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 8, 200019])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2e940914",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 8, 200019])\n"
     ]
    }
   ],
   "source": [
    "probas = torch.softmax(logits, dim=-1)\n",
    "print(probas.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "394f1e1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[4.2369e-06, 1.9948e-06, 2.6355e-06,  ..., 3.0819e-06,\n",
       "          5.7465e-06, 1.6902e-06],\n",
       "         [6.5892e-06, 1.6625e-06, 6.2114e-06,  ..., 7.2826e-06,\n",
       "          6.6397e-06, 3.6026e-06],\n",
       "         [3.6242e-06, 4.5758e-06, 6.0980e-06,  ..., 3.7388e-06,\n",
       "          1.1860e-05, 1.4350e-06],\n",
       "         ...,\n",
       "         [1.1959e-05, 3.8941e-06, 4.6082e-06,  ..., 3.9672e-06,\n",
       "          7.8944e-06, 6.7520e-06],\n",
       "         [5.4063e-06, 2.0371e-06, 6.5283e-06,  ..., 3.8506e-06,\n",
       "          4.0004e-06, 3.1869e-06],\n",
       "         [4.0427e-06, 1.7514e-06, 8.6368e-06,  ..., 1.2341e-05,\n",
       "          1.1058e-06, 6.4744e-06]]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4aa47c42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token IDs: tensor([[[ 89054],\n",
      "         [199706],\n",
      "         [123900],\n",
      "         [188689],\n",
      "         [ 69453],\n",
      "         [ 69048],\n",
      "         [  8870],\n",
      "         [122900]]])\n"
     ]
    }
   ],
   "source": [
    "token_ids = torch.argmax(probas, dim=-1, keepdim=True)\n",
    "print(\"Token IDs:\", token_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8206f149",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Targets batch: drogi prowadzą do Rzymu\n",
      "Outputs batch:  dvePhilip njem verdwijnenintern Rearら сест\n"
     ]
    }
   ],
   "source": [
    "print(f\"Targets batch: {token_ids_to_text(targets[0], tokenizer)}\")\n",
    "print(f\"Outputs batch: {token_ids_to_text(token_ids[0].flatten(), tokenizer)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2f32346b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target probabilities: tensor([6.1825e-06, 3.1068e-06, 7.2742e-06, 2.8316e-06, 5.9877e-06, 4.8219e-06,\n",
      "        5.0395e-06, 9.6494e-06])\n"
     ]
    }
   ],
   "source": [
    "text_idx = 0\n",
    "target_probas = probas[text_idx, -1, targets[text_idx]]\n",
    "print(\"Target probabilities:\", target_probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7b585bb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log probabilities: tensor([-11.9938, -12.6819, -11.8312, -12.7747, -12.0258, -12.2424, -12.1982,\n",
      "        -11.5486])\n"
     ]
    }
   ],
   "source": [
    "log_probs = torch.log(target_probas)\n",
    "print(\"Log probabilities:\", log_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0b5ad618",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(12.1621)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-1 * torch.mean(log_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c31b55d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(12.4225)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.nn.functional.cross_entropy(\n",
    "    logits.flatten(0, 1),\n",
    "    targets.flatten())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a593cc43",
   "metadata": {},
   "source": [
    "### 3) Calculating the training and validation set losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9acdd3d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import create_dataloader_v1\n",
    "\n",
    "text_file = \"../data_brzechwa.txt\"\n",
    "text_data = open(text_file, \"r\", encoding=\"utf-8\").read()\n",
    "train_ratio = 0.9\n",
    "split_idx = int(len(text_data) * train_ratio)\n",
    "train_data = text_data[:split_idx]\n",
    "val_data = text_data[split_idx:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "65960c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(123)\n",
    "\n",
    "train_loader = create_dataloader_v1(\n",
    "    train_data,\n",
    "    batch_size=2,\n",
    "    max_length=GPT_CONFIG_124M[\"context_length\"],\n",
    "    stride=GPT_CONFIG_124M[\"context_length\"],\n",
    "    drop_last=True,\n",
    "    shuffle=True,\n",
    "    num_workers=0\n",
    ")\n",
    "\n",
    "val_loader = create_dataloader_v1(\n",
    "    val_data,\n",
    "    batch_size=2,\n",
    "    max_length=GPT_CONFIG_124M[\"context_length\"],\n",
    "    stride=GPT_CONFIG_124M[\"context_length\"],\n",
    "    drop_last=False,\n",
    "    shuffle=False, \n",
    "    num_workers=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b77bb559",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loader: \n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n"
     ]
    }
   ],
   "source": [
    "print(\"Train loader: \")\n",
    "for x, y in train_loader:\n",
    "    pass\n",
    "print(x.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "aa1f7e1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loader: \n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n"
     ]
    }
   ],
   "source": [
    "print(\"Val loader: \")\n",
    "for x, y in val_loader:\n",
    "    pass\n",
    "print(x.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5f899cfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train tokens: 183296\n",
      "Val tokens: 19968\n",
      "Total tokens: 203264\n"
     ]
    }
   ],
   "source": [
    "train_tokens = 0\n",
    "for input_batch, target_batch in train_loader:\n",
    "    train_tokens += input_batch.numel()\n",
    "\n",
    "val_tokens = 0\n",
    "for input_batch, target_batch in val_loader:\n",
    "    val_tokens += input_batch.numel()\n",
    "\n",
    "print(f\"Train tokens: {train_tokens}\")\n",
    "print(f\"Val tokens: {val_tokens}\")\n",
    "print(f\"Total tokens: {train_tokens + val_tokens}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1e08bd91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5a9b9551",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_loss_batch(input_batch, target_batch, model, device):\n",
    "    input_batch, target_batch = input_batch.to(device), target_batch.to(device)\n",
    "    logits = model(input_batch)\n",
    "    loss = torch.nn.functional.cross_entropy(logits.flatten(0,1), target_batch.flatten())\n",
    "    return loss\n",
    "\n",
    "def calc_loss_loader(data_loader, model, device, num_batches=None):\n",
    "    total_loss = 0.\n",
    "    if len(data_loader) == 0:\n",
    "        return float(\"nan\")\n",
    "    elif num_batches is None:\n",
    "        num_batches = len(data_loader)\n",
    "    else:\n",
    "        num_batches = min(num_batches, len(data_loader))\n",
    "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
    "        if i < num_batches:\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            total_loss += loss.item()\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    return total_loss / num_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c347240",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(123)\n",
    "\n",
    "with torch.no_grad():\n",
    "    train_loss = calc_loss_loader(train_loader, model, device)\n",
    "    val_loss = calc_loss_loader(val_loader, model, device)\n",
    "print(f\"Train loss: {train_loss:.4f}\")\n",
    "print(f\"Val loss: {val_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a8b56b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.exp(torch.tensor([]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
