{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b2e228a6",
   "metadata": {},
   "source": [
    "## Pretraining on unlabeled data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88f13d70",
   "metadata": {},
   "source": [
    "### 1) Evaluating generative text models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a47cd118",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import GPTModel\n",
    "import torch\n",
    "\n",
    "GPT_CONFIG_124M = {\n",
    "    \"vocab_size\": 200019,\n",
    "    \"context_length\": 1024,\n",
    "    \"emb_dim\": 768,\n",
    "    \"n_heads\": 12,\n",
    "    \"n_layers\": 12,\n",
    "    \"drop_rate\": 0.1,\n",
    "    \"qkv_bias\": False\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ba679878",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(123)\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d08ab0fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "from utils import generate_text_simple\n",
    "\n",
    "def text_to_token_ids(text, tokenizer):\n",
    "    encoded = tokenizer.encode(text, allowed_special={\"<|endoftext|>\"})\n",
    "    encoded_tensor = torch.tensor(encoded).unsqueeze(0)\n",
    "    return encoded_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "49cfb5b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input IDs: tensor([[152687,   8811,   3705, 155653,    286,   2453,   3008,  12637]])\n"
     ]
    }
   ],
   "source": [
    "start_context = \"Pierwszy dzień wiosny jest\"\n",
    "tokenizer = tiktoken.get_encoding(\"o200k_base\")\n",
    "input_ids = text_to_token_ids(start_context, tokenizer)\n",
    "print(\"Input IDs:\", input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c06c7ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def token_ids_to_text(token_ids, tokenizer):\n",
    "    decoded = tokenizer.decode(token_ids.squeeze(0).tolist())\n",
    "    return decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c73251bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token IDs to text: <function token_ids_to_text at 0x7e2151c21e40>\n"
     ]
    }
   ],
   "source": [
    "token_ids_to_text(input_ids, tokenizer)\n",
    "print(\"Token IDs to text:\", token_ids_to_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2126a171",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_ids = generate_text_simple(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(start_context, tokenizer),\n",
    "    max_new_tokens=10,\n",
    "    context_size=GPT_CONFIG_124M[\"context_length\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4116fa9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([152687,   8811,   3705, 155653,    286,   2453,   3008,  12637,   2944,\n",
       "         32600,  10819,  29864,  14338, 160118,  91249, 189492, 135305,  65540])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_ids.squeeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8b33575e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Pierwszy dzień wiosny jest monthibileosingGP branch Wolfs hướng serien தொகету'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_ids_to_text(token_ids, tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37d9b2e5",
   "metadata": {},
   "source": [
    "### 2) Calculating the text generation loss: cross-entropy and perplexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bf67719e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[    54, 148556,  51201,   6517,   6248, 104788,  21589,    621]])\n",
      "tensor([[100256,   6248, 104788,  21589,    621,    460,  28178,     84]])\n"
     ]
    }
   ],
   "source": [
    "inputs = text_to_token_ids(\"Wszystkie drogi prowadzą do\", tokenizer)\n",
    "print(inputs)\n",
    "targets = text_to_token_ids(\"drogi prowadzą do Rzymu\", tokenizer)\n",
    "print(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0399ace9",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    logits = model(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "65f35bf7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 8, 200019])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2e940914",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 8, 200019])\n"
     ]
    }
   ],
   "source": [
    "probas = torch.softmax(logits, dim=-1)\n",
    "print(probas.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "394f1e1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[5.4583e-06, 5.1334e-06, 4.4685e-06,  ..., 7.7346e-06,\n",
       "          4.0741e-06, 2.8078e-06],\n",
       "         [8.1417e-06, 4.7167e-06, 1.7018e-05,  ..., 1.8737e-05,\n",
       "          1.5956e-05, 3.2252e-06],\n",
       "         [1.1007e-05, 5.4918e-06, 4.6825e-06,  ..., 3.5426e-06,\n",
       "          3.4522e-06, 4.5152e-06],\n",
       "         ...,\n",
       "         [6.6834e-06, 1.9917e-06, 5.3639e-06,  ..., 6.2616e-06,\n",
       "          4.3297e-06, 2.4443e-06],\n",
       "         [4.5537e-06, 3.7555e-06, 7.1191e-06,  ..., 3.2698e-06,\n",
       "          5.6970e-06, 4.2523e-06],\n",
       "         [6.2523e-06, 2.0468e-06, 2.9966e-06,  ..., 2.4268e-06,\n",
       "          3.7407e-06, 9.4331e-06]]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4aa47c42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token IDs: tensor([[[ 99330],\n",
      "         [ 26909],\n",
      "         [  4071],\n",
      "         [ 21347],\n",
      "         [183194],\n",
      "         [191723],\n",
      "         [113220],\n",
      "         [122132]]])\n"
     ]
    }
   ],
   "source": [
    "token_ids = torch.argmax(probas, dim=-1, keepdim=True)\n",
    "print(\"Token IDs:\", token_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8206f149",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Targets batch: drogi prowadzą do Rzymu\n",
      "Outputs batch: ZIPৰু dire debut משום goofy vroegerartig\n"
     ]
    }
   ],
   "source": [
    "print(f\"Targets batch: {token_ids_to_text(targets[0], tokenizer)}\")\n",
    "print(f\"Outputs batch: {token_ids_to_text(token_ids[0].flatten(), tokenizer)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2f32346b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target probabilities: tensor([2.0819e-06, 8.7382e-06, 3.2365e-06, 3.3469e-06, 1.8273e-06, 2.4464e-06,\n",
      "        5.1523e-06, 4.0019e-06])\n"
     ]
    }
   ],
   "source": [
    "text_idx = 0\n",
    "target_probas = probas[text_idx, -1, targets[text_idx]]\n",
    "print(\"Target probabilities:\", target_probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7b585bb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log probabilities: tensor([-13.0822, -11.6478, -12.6410, -12.6075, -13.2127, -12.9209, -12.1761,\n",
      "        -12.4287])\n"
     ]
    }
   ],
   "source": [
    "log_probs = torch.log(target_probas)\n",
    "print(\"Log probabilities:\", log_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0b5ad618",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(12.5896)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-1 * torch.mean(log_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c31b55d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(12.6042)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.nn.functional.cross_entropy(\n",
    "    logits.flatten(0, 1),\n",
    "    targets.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88f18094",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
